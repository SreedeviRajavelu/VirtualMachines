{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Sree Devi's Documentation on Virtual Machines, Docker &amp; Networking","text":"<p>Welcome! Use the sidebar to navigate to different sections of this project.</p>"},{"location":"#docker","title":"Docker","text":"<ul> <li>Docker Build</li> <li>Docker Networking</li> <li>Communication Between Inside &amp; Outside Docker</li> <li>Docker Container Interfaces</li> <li>Docker Engine on Ubuntu</li> <li>Using tarballs (.tgz)</li> </ul>"},{"location":"#virtualization","title":"Virtualization","text":"<ul> <li>VM-to-VM Communication</li> <li>Fix Slow Ubuntu VM Boot</li> </ul>"},{"location":"#tools","title":"Tools","text":"<ul> <li>SSH Setup</li> <li>Matlab Setup</li> <li>Wine on Linux</li> </ul>"},{"location":"#scada","title":"SCADA","text":"<ul> <li>ScadaLTS</li> </ul>"},{"location":"#os","title":"OS","text":"<ul> <li>Mac Notes</li> </ul>"},{"location":"CommunicationBetweenInsideAndOutsideDocker/","title":"Communication Inside & Outside Docker","text":"<p>what does this mean and should I try connecting to this ip address if I have an sql database in a docker container on Macbook and I'm trying to connect to it from a python script inside an ubuntu vm in virtual box</p> <p>sreedevirajavelu@srees-MacBook-Air ~ % ipconfig getifaddr en0</p> <p>10.34.11.15 sreedevirajavelu@srees-MacBook-Air ~ % </p> <p>The IP address <code>10.34.11.15</code> is your MacBook\u2019s local network IP address on the <code>en0</code> interface (usually Wi-Fi).</p>"},{"location":"CommunicationBetweenInsideAndOutsideDocker/#what-this-means-for-your-setup","title":"What this means for your setup:","text":"<ul> <li>Your MacBook\u2019s Docker container MySQL is running on <code>localhost</code> inside your MacBook.</li> <li>Your Ubuntu VM in VirtualBox is a separate machine from the MacBook host.</li> <li>The VM needs to reach the Docker container through your MacBook\u2019s network IP (10.34.11.15) if networking between the VM and the Mac is set up properly.</li> </ul>"},{"location":"CommunicationBetweenInsideAndOutsideDocker/#can-you-connect-to-the-mysql-docker-container-on-ip-10341115-from-the-ubuntu-vm","title":"Can you connect to the MySQL Docker container on IP <code>10.34.11.15</code> from the Ubuntu VM?","text":"<p>It depends on the VirtualBox network mode:</p> <ol> <li> <p>NAT (default):</p> </li> <li> <p>The VM is behind a NAT and cannot directly access host IP like <code>10.34.11.15</code>.</p> </li> <li> <p>You would need to set up port forwarding in VirtualBox to forward the host port 3306 to the VM or use other tricks.</p> </li> <li> <p>Bridged Adapter:</p> </li> <li> <p>The VM gets an IP on the same LAN as your MacBook.</p> </li> <li> <p>VM can directly access <code>10.34.11.15</code> on port 3306 if firewall allows.</p> </li> <li> <p>Host-only Adapter:</p> </li> <li> <p>VM and host can communicate using a special virtual network IP (not the LAN IP).</p> </li> <li>You\u2019d check the IP of the host on that virtual network interface.</li> </ol>"},{"location":"CommunicationBetweenInsideAndOutsideDocker/#what-should-you-do","title":"What should you do?","text":"<ul> <li> <p>Check your VM\u2019s network mode in VirtualBox settings.</p> </li> <li> <p>If it\u2019s NAT, either:</p> </li> <li> <p>Switch to Bridged Adapter mode for the VM to be on the same LAN as the Mac, or</p> </li> <li> <p>Set up port forwarding in VirtualBox (host port 3306 \u2192 VM port 3306).</p> </li> <li> <p>Try to ping the MacBook\u2019s IP (<code>10.34.11.15</code>) from inside the Ubuntu VM:</p> </li> </ul> <pre><code>ping 10.34.11.15\n</code></pre> <p>If ping works and firewall allows, you can try to connect to MySQL at <code>10.34.11.15:3306</code> from your Python script running in the VM.</p>"},{"location":"CommunicationBetweenInsideAndOutsideDocker/#summary","title":"Summary","text":"Your Mac IP VM network type Access from VM to MySQL container? <code>10.34.11.15</code> NAT No direct access without port forwarding <code>10.34.11.15</code> Bridged Adapter Yes, direct access if firewall allows VirtualBox host-only IP Host-only Adapter Access via that network IP, not <code>10.34.11.15</code> <p>If you want, I can guide you how to set up VirtualBox network so the VM can access your Docker MySQL on the Mac!</p>"},{"location":"DockerBuild/","title":"Docker Build","text":""},{"location":"DockerBuild/#building-docker-images","title":"Building Docker images","text":"<p><code>docker build --network host --tag database .</code></p> <p>What each part does: - <code>docker build</code>: command to build a Docker image - <code>--network host</code>: uses host's network stack during the build process (allows the build to access network resources as if it were running directly on the host machine) - <code>--tag database</code>: tags (names) the resulting image as \"database\" - <code>.</code>: uses current directory as the build context (where Docker looks for the Dockerfile and any files it needs to copy)   - <code>--network host</code>: this flag is often used when the build process needs to download packages or access network resources that might be blocked by Docker's default networking.</p>"},{"location":"DockerEngine_Ubuntu/","title":"Docker Engine on Ubuntu","text":"<p>Steps to install Docker Engine on ubuntu 24.04.2 :</p> <ul> <li>https://docs.docker.com/engine/install/ubuntu/</li> </ul> <p>Check ubuntu version using:</p> <ul> <li><code>lsb_release -a</code></li> <li><code>cat /etc/os-release</code></li> </ul> <p></p> <p>Check CPU architecture - <code>uname -m</code></p> <ul> <li>x86_64 \u2192 64-bit Intel/AMD (amd64) \u2705 supported</li> <li>aarch64 \u2192 64-bit ARM (arm64) \u2705 supported</li> <li>armv7l \u2192 32-bit ARM \u274c not supported by Docker Engine</li> <li>s390x, ppc64le \u2192 supported but only on special hardware</li> </ul> <p>On a VirtualBox VM on a MacBook, you\u2019ll almost certainly see x86_64 if your Mac is Intel-based, or aarch64 if your MacBook is Apple Silicon (M1/M2/M3).</p> <p></p>"},{"location":"Docker_Container_Interfaces/","title":"Docker Container Interfaces","text":""},{"location":"Docker_Container_Interfaces/#docker-container-interfaces","title":"Docker Container Interfaces","text":"<ul> <li><code>ip a</code> inside the docker container of an IED after <code>docker exec -it ds1cb1 bash</code>:</li> </ul> <p>Different use cases of the 2 network interfaces:</p> <ol> <li> <p><code>eth0 : 10.0.1.6/24</code></p> </li> <li> <p>Default interface created when the container is attached to a Docker network (bridge, overlay, or custom)      Use case:</p> <ul> <li>Used for container-to-container communication inside the same Docker network</li> <li>Other containers on the same network (subnet <code>10.0.1.0/24</code>) can reach this container via <code>10.0.1.6</code></li> <li>Not directly routable from the host machine unless you expose ports (via <code>-p host_port:container_port</code>)    Example:</li> <li>If you have another container on the same Docker network, it can <code>ping 10.0.1.6</code> or connect directly to its services.</li> </ul> </li> <li> <p><code>eth1 : 172.24.10.11/24</code></p> </li> <li>A second interface \u2014 likely because you attached this container to another Docker network (such as with <code>--network</code> flag or via Docker Compose multiple networks)      Use case:<ul> <li>Provides connectivity to containers/services on the <code>172.24.10.0/24</code> subnet</li> <li>Might be used for external integration (such as simulating a \"backend network\" while <code>eth0</code> handles a \"frontend network\")</li> <li>Useful in multi-network setups, where a container acts as a bridge between 2 networks    Example:</li> <li>If you are running a database container on the <code>172.24.10.0/24</code> network, this container can talk to it via <code>172.24.10.x</code></li> </ul> </li> </ol>"},{"location":"Docker_Container_Interfaces/#which-ip-can-you-use-from-the-host-machine","title":"Which IP can you use from the host machine?","text":"<ul> <li>Normally, you don't use these internal container IPs from the host.</li> <li>Instead:</li> <li>Use localhost (127.0.0.1) on the host with port mappings (-p 8080:80)</li> <li>If using macvlan/host networks, the container may be directly reachable on one of these IPs (<code>10.0.1.6</code> or <code>172.24.10.11</code>) from the host or even other machines on the LAN.</li> </ul>"},{"location":"Docker_Container_Interfaces/#summary","title":"Summary:","text":"<ul> <li><code>eth0 (10.0.1.6)</code> : main Docker network, container-to-container communication.</li> <li><code>eth1 (172.24.10.0)</code>: secondary Docker network, used if container needs to talk to another isolated group of services.</li> <li>From the host, you usually connect via <code>localhost</code>+ published ports, unless you intentionally configured a special network (macvlan, host, overlay).</li> </ul> <p>To check if these IPs are reachable directly from host or internal-only :</p> <p>...to be continued...</p>"},{"location":"Docker_Networks/","title":"Docker Networking","text":""},{"location":"Docker_Networks/#docker-networking-tutorial-bridge-none-host-ipvlan-macvlan-overlay","title":"Docker Networking Tutorial (Bridge - None - Host - IPvlan - Macvlan - Overlay)","text":"<p>Reference: https://youtu.be/fBRgw5dyBd4?si=LodjJDx4AdnjYOS6</p>"},{"location":"Docker_Networks/#docker-bridge","title":"Docker Bridge","text":"<ul> <li>2 segments that the bridge connects is:</li> <li>local host e.g. your laptop, or linux server where you run your Docker containers</li> <li>virtual network created by Docker</li> <li></li> </ul>"},{"location":"Docker_Networks/#when-you-install-docker-for-the-first-time-it-will-create-a-default-bridge-network-on-the-host-slightly-different-on-macos-as-it-will-run-al-containers-inside-a-linux-vm-virtualization-framework","title":"When you install Docker for the first time, it will create a default bridge network on the host (slightly different on MacOS as it will run al containers inside a Linux VM, virtualization framework)","text":"<ul> <li>all containers you create on that host will get an IP address on that range</li> </ul> <p>On a Linux host, Docker Engine directly creates a docker0 bridge network interface in the host\u2019s network stack. That\u2019s the familiar default bridge you see with ifconfig or ip a (usually 172.17.0.1/16). </p> <p>On a Mac (macOS) or Windows, things are different:</p> <p>Docker Desktop does not create a native docker0 bridge interface on your MacBook\u2019s network stack.</p> <p>Instead, Docker Desktop runs all containers inside a lightweight Linux VM (on macOS, this is managed using Apple\u2019s HyperKit or now a Virtualization Framework).</p> <p>Inside that VM, Docker does create a docker0 bridge (just like on Linux). But this bridge is inside the VM, not on macOS itself.</p> <p>From your MacBook\u2019s perspective, you won\u2019t see docker0 if you run ifconfig or ip a. Instead, Docker Desktop sets up a special networking layer that forwards traffic between your MacBook and the VM.</p> <p>So to answer directly:</p> <p>\ud83d\udc49 No, Docker Desktop does not create a default bridge network on your MacBook\u2019s host network stack. \ud83d\udc49 Yes, it does create a default bridge network inside the Linux VM where your containers run.</p> <p>If you run: <code>docker network ls</code> you\u2019ll still see bridge, host, and none listed, because those networks exist in the Docker VM environment, even though your Mac itself doesn\u2019t expose them as interfaces.</p> <p>Do you want me to also explain how you can check the actual IP range of the bridge network inside Docker Desktop on your Mac?</p>"},{"location":"Docker_Networks/#containers-created-in-the-default-bridge-network","title":"Containers created in the default bridge network","text":"<ul> <li>can communicate with each other</li> <li>default bridge network has restrictions and is not recommended for production, better to use user-defined bridge network.</li> <li>Default bridge network: Cannot use container DNS from host </li> <li>In default bridge network, DNS is not supported. Also cannot use DNS to send requests between containers.</li> </ul>"},{"location":"Docker_Networks/#user-defined-bridge-network","title":"User defined bridge network**:","text":"<ul> <li>Can use DNS to send requests to containers. </li> <li>This only applies to communications inside the bridge network between containers. You still will NOT be able to use the container DNS from the host.</li> </ul>"},{"location":"Docker_Networks/#host-mode-networking-option","title":"Host mode - networking option","text":"<ul> <li>container will not get its own IP and instead share the same networking namespace as the host where you run the container</li> <li>will appear as if you were running a regular application on that host</li> <li>thus any application running on a different server will be able to access the container using the host's IP address</li> </ul>"},{"location":"Docker_Networks/#ipvlan-network","title":"IPvlan network:","text":"<ul> <li>Traditionally, to expose a container to the outside world we used bridge network. But it adds additional complexity and performance penalty. Packet needs to go through additional hop, need to map ports from the container to the host to expose it to other applications.  </li> <li>Does not use a bridge for isolation and is associated directly with the Linux network interface. No need for port mappings in these scenarios.</li> </ul>"},{"location":"Docker_Networks/#macvlan-network","title":"MacVLAN network:","text":"<ul> <li>Some legacy applications and those that monitor network traffic expect to be directly connected to the physical network.</li> <li>In this case, can use the MacVLAN network driver to assign a MAC address to each container's virtual network interface.</li> <li>It will appear as a physical network interface directly connected to the physical network.</li> <li>to create it, must specify the subnet that the host uses, the gateway, and the parent network interface</li> <li>compare the parent MAC address (parent interface) -&gt; e.g. ip addr show ens33</li> <li>MAC address of the container -&gt; ssh into it and do <code>ip addr</code></li> </ul>"},{"location":"Docker_Networks/#difference-between-ipvlan-and-macvlan","title":"Difference between IPVLAN and MACVLAN:","text":"<ul> <li>if use IPVLAN: container will get the same MAC address as your host</li> <li>if use MACVLAN: container will have a different MAC address from host</li> </ul>"},{"location":"Docker_Networks/#overlay-network","title":"Overlay network","text":"<ul> <li>When you deploy your applications to production, you will need more than one physical or virtual server, each with a Docker daemon installed.</li> <li>The overlay network driver creates a distributed network among multiple Docker daemon hosts.</li> <li>This network sits on top of (overlays) the host-specific networks, allowing containers connected to it to communicate securely, especially when encryption is enabled.</li> <li>Most frequently, this type of network is used with Docker Swarm , but it is also possible to connect individual containers.</li> <li>Comment from youtuber: to manage containers at scale, especially in production, consider using Kubernetes.</li> <li>need to disable</li> <li>Example of usage of overlay network:</li> <li><code>2 ubuntu VMs</code></li> <li>find network interfaces on both VMs, e.g. ens33 on both VMs -&gt; disable this on the network interface on both VMs</li> <li><code>sudo ethtool -K ens33 tx-checksum-ip-generic off</code> (not persistent across restarts so might need to use something like a script using systemd service to automatically run it on boot)</li> <li>Even if you want to connect individual containers to overlay network, we still need to initialize the Docker Swarm</li> <li>on the first VM, run <code>docker swarm init</code></li> <li>will give a command you can execute on other VMs to join the Docker Swarm</li> <li>each VM must have docker installed</li> <li>manager and worker nodes (the VMs)</li> <li>on manager, create an overlay network and an attachable flag for individual containers to be able to use this network. Otherwise only swarm services will be able to use it.</li> <li>on the worker node (VM) if you do <code>docker network ls</code>, you will only see the overlay network when you start a container that uses the network (can start on the manager node)</li> <li>to verify that we can access containers on that overlay network deployed on different VMs, can SSH to the second container and use curl to send a request to the first container on the manager node</li> <li></li> </ul>"},{"location":"Docker_Networks/#overlay-networks","title":"Overlay Networks","text":"<ul> <li>Allow containers running on different Docker hosts (machines) to communicate with each other as if they are on the same local network, while keeping the communcation secure and isolated.</li> </ul> <p>Why normal Docker networks is not enough? - By default, Docker creates a bridge network on a single host (like bridge0 on Linux) - Containers connected to this bridge can talk to each other, but only on the same host.</p> <p>If you want:  - multiple physical/virtual servers - running containers that need to talk to each other - Need something that span across hosts</p>"},{"location":"Docker_Networks/#how-overlay-networks-work","title":"How overlay networks work?","text":"<ul> <li>Docker creates a virtual distributed network that spans all participating nodes (hosts).</li> <li>uses VXLAN tunneling (encapsulating packets inside UDP) so that container-to-container traffic can move across hosts transparently.</li> <li>network is managed by Docker swarm or Docker engine in swarm mode</li> </ul> <p>Example: - Host A has a container running web. - Host B has a container running db. - Both containers join the same overlay network called backend-net. - Now web can talk to db using the container name (db:3306), even though they are on different machines.</p>"},{"location":"Docker_tgz/","title":"Using tarballs (.tgz)","text":""},{"location":"Docker_tgz/#what-is-a-docker-tgz-file","title":"What is a Docker .tgz file ?","text":"<p>In the Docker context, a <code>.tgz</code> file is a compressed archive of a Docker image created with:</p> <pre><code>  docker save -o image.tar &lt;image:tag&gt;\n\n  # then gzip it\n\n  tar czf image.tgz image.tar\n</code></pre> <p>Or directly:</p> <p><code>docker save &lt;image:tag&gt; | gzip &gt; image.tgz</code></p> <p>Inside the <code>.tgz</code>: - it is basically a tarball of JSON metadata and filesystem layer tarballs</p>"},{"location":"Docker_tgz/#to-make-modifications-to-docker-tgz-file","title":"To make modifications to Docker .tgz file","text":"<ul> <li>load the <code>.tgz</code> file into Docker (<code>docker load</code>)</li> <li>run a container from it</li> <li>make changes</li> <li><code>docker commit</code></li> <li><code>docker save</code></li> </ul>"},{"location":"Docker_tgz/#do-changes-to-tgz-persist","title":"Do changes to .tgz persist?","text":"<ul> <li>if you only change inside the running container from image, these changes don't go back into the .tgz. They live in the container's writable layer.</li> <li>To persist changes into a new <code>.tgz</code>:</li> <li>Run a container from the image</li> <li>Make modifications</li> <li>Commit the container -&gt; new image   <code>docker commit &lt;container-id&gt; myimage:modified</code></li> <li>Save it back:   <code>docker save myimage:modified | gzip &gt; myimage-modified.tgz</code></li> </ul> <p>## How .tgz files work in practice  - <code>.tgz</code> = portable snapshot of a Docker image  - you can transfer it, then use docker load &lt; my image.tgz to load it into Docker on another host  -  mostly for air-gapped environments (no Docker Hub access) or backups.</p>"},{"location":"Docker_tgz/#to-load-the-tgz-into-docker","title":"To load the .tgz into Docker","text":"<p><code>docker load &lt; myimage.tgz</code></p> <ul> <li>makes the image available locally so you can run containers from it</li> </ul>"},{"location":"Docker_tgz/#to-create-a-tgz-from-an-existing-image","title":"To create a .tgz from an existing image","text":"<p><code>docker save myimage:tag | gzip &gt; myimage.tgz</code> - now you can copy over myimage.tgz to another machine and docker load it there</p> <p>sreedevirajavelu@srees-MacBook-Air pgtwin_7ss % docker load -i 7ss_db_docker_20250218.tgz  unrecognized image format</p> <p>That error means the file 7ss_db_docker_20250218.tgz is not in the expected Docker save/load format. Let\u2019s debug step by step:</p> <ol> <li>What docker load expects <code>docker load -i file.tgz</code> only works if the archive was created using:</li> </ol> <p><code>docker save -o image_name.tgz image:tag</code></p> <p>This produces a tarball with manifest.json, repositories, and layer directories inside.</p> <p>If your .tgz was created another way (e.g., tar czf on a Docker context or folder), docker load will reject it.</p> <ol> <li>Check the contents of your .tgz</li> </ol> <p>Run on your MacBook: tar -tzf 7ss_db_docker_20250218.tgz | head -20 If you see manifest.json and layer directories \u2192 \u2705 this is a docker save image, and something else is wrong. If you see Dockerfile, requirements.txt, Panda-db/, etc. \u2192 \u274c this is just the build context, not an image.</p> <ol> <li>If it\u2019s a Docker context (not an image)</li> </ol> <p>You cannot load it directly. Instead you need to build: tar -xzf 7ss_db_docker_20250218.tgz -C ./extracted/ cd extracted docker build -t my-image:latest .</p> <ol> <li>If it is a valid docker save image</li> </ol> <p>Try re-loading: gunzip -c 7ss_db_docker_20250218.tgz | docker load (some tools produce gzip-compressed vs tar-compressed files differently).</p> <p>sreedevirajavelu@srees-MacBook-Air pgtwin_7ss % tar -tzf 7ss_db_docker_20250218.tgz | head -20</p> <p>7ss_db/</p> <p>7ss_db/docker-sql/</p> <p>7ss_db/docker-sql/pgtv4_pp_7ss_db_20240302.sql</p> <p>7ss_db/docker-sql/my.cnf</p> <p>7ss_db/docker-sql/build_fixed_max_conn.sh</p> <p>7ss_db/docker-sql/build.sh</p> <p>7ss_db/docker-sql/pandapower_db_initial.sql</p> <p>7ss_db/docker-sql/prepare_max_connections.py</p> <p>7ss_db/docker-sql/README.md</p> <p>7ss_db/docker-sql/pandapower_db_structure.sql</p> <p>7ss_db/docker-sql/Dockerfile</p> <p>7ss_db/docker-sql/run_db.sh</p> <p>sreedevirajavelu@srees-MacBook-Air pgtwin_7ss % </p>"},{"location":"Fix_Slow_UbuntuVM_Boot/","title":"Fix slow booting for ubuntu vm based on output of these commands to find what was slowing down the booting time","text":"<pre><code> systemd-analyze\n systemd-analyze blame\n</code></pre> <p>Top delay:</p> <p>2min 258ms systemd-networkd-wait-online.service</p> <p>This service alone adds over 2 minutes to your boot. That\u2019s practically your entire userspace delay.</p> <p>\ud83d\udd0d What is systemd-networkd-wait-online.service?</p> <p>It waits for the network to be fully up (like getting a DHCP lease or full connection). Used mostly on servers to ensure critical services only start after network is available. In most VMs and desktops, it's not necessary and can be safely disabled.</p> <p>\u2705 Fix: Disable the Wait-Online Service</p> <p>Run: - sudo systemctl disable systemd-networkd-wait-online.service - sudo systemctl mask systemd-networkd-wait-online.service</p> <p>\ud83d\udca1 mask ensures it cannot be accidentally started again.</p> <p>If you also see or use NetworkManager, you can disable its wait service too:</p> <p>sudo systemctl disable NetworkManager-wait-online.service</p> <p>sudo systemctl mask NetworkManager-wait-online.service</p> <p>\ud83d\udd01 Then reboot your VM: sudo reboot \ud83e\uddea After reboot:</p> <p>Check again: systemd-analyze You should see your boot time drop from 2+ minutes \u2192 ~15 seconds or less.</p> <p>\ud83d\udd01 To Undo the Effects of Disabling and Masking the Wait-Online Service If you previously ran:</p> <ul> <li> <p>sudo systemctl disable systemd-networkd-wait-online.service</p> </li> <li> <p>sudo systemctl mask systemd-networkd-wait-online.service</p> </li> </ul> <p>You can restore the service like this:</p> <p>\u2705 Step 1: Unmask the service</p> <ul> <li>sudo systemctl unmask systemd-networkd-wait-online.service</li> </ul> <p>\u2705 Step 2: Re-enable the service at boot</p> <ul> <li>sudo systemctl enable systemd-networkd-wait-online.service \u2705 Step 3 (Optional): Start it immediately (not needed for reboot use)</li> </ul> <p>sudo systemctl start systemd-networkd-wait-online.service</p> <p>\ud83d\udd01 Same steps apply if you disabled NetworkManager-wait-online.service: Just replace the service name in each command. Example:</p> <p>sudo systemctl unmask NetworkManager-wait-online.service</p> <p>sudo systemctl enable NetworkManager-wait-online.service</p> <p>\ud83e\uddea Confirm it's active again:</p> <p>systemctl status systemd-networkd-wait-online.service or systemctl is-enabled systemd-networkd-wait-online.service</p> <p>You should see:</p> <p><code>enabled</code></p> <p>\u2705 Summary: Rollback Commands</p>"},{"location":"Fix_Slow_UbuntuVM_Boot/#unmask-and-re-enable-systemd-networkd-wait-online","title":"Unmask and re-enable systemd-networkd-wait-online","text":"<p>sudo systemctl unmask systemd-networkd-wait-online.service</p> <p>sudo systemctl enable systemd-networkd-wait-online.service</p>"},{"location":"Fix_Slow_UbuntuVM_Boot/#optional-also-for-networkmanager-wait-online-if-previously-masked","title":"Optional: Also for NetworkManager-wait-online (if previously masked)","text":"<p>sudo systemctl unmask NetworkManager-wait-online.service</p> <p>sudo systemctl enable NetworkManager-wait-online.service</p>"},{"location":"Mac/","title":"Mac Notes","text":""},{"location":"Mac/#setting-up-ubuntu-vm-on-virtualbox-on-macbook-m4","title":"Setting up Ubuntu VM on VirtualBox on MacBook M4 :","text":"<p>https://www.youtube.com/watch?v=LjL_N0OZxvY</p>"},{"location":"Mac/#make-ubuntu-full-screen-in-virtualbox","title":"Make Ubuntu full screen in VirtualBox:","text":"<p>https://youtu.be/Fw8ppXeJ_GY?si=qu0ehtCFotNpaLcB - this tutorial also shows how to install guest additions</p>"},{"location":"Mac/#how-to-create-shared-folder-between-host-and-ubuntu-vm-on-virtualbox","title":"How to create shared folder between host and Ubuntu VM on VirtualBox:","text":"<p>https://youtu.be/j8Ne96h8UDg?si=aBwXLuINWmvPNp1l</p> <p>Fix slow booting for ubuntu vm based on output of these commands to find what was slowing down the booting time</p> <pre><code> systemd-analyze\n systemd-analyze blame\n</code></pre> <p></p> <p>Top delay:</p> <p>2min 258ms systemd-networkd-wait-online.service</p> <p>This service alone adds over 2 minutes to your boot. That\u2019s practically your entire userspace delay.</p> <p>\ud83d\udd0d What is systemd-networkd-wait-online.service?</p> <p>It waits for the network to be fully up (like getting a DHCP lease or full connection). Used mostly on servers to ensure critical services only start after network is available. In most VMs and desktops, it's not necessary and can be safely disabled.</p> <p>\u2705 Fix: Disable the Wait-Online Service</p> <p>Run: - sudo systemctl disable systemd-networkd-wait-online.service - sudo systemctl mask systemd-networkd-wait-online.service</p> <p>\ud83d\udca1 mask ensures it cannot be accidentally started again.</p> <p>If you also see or use NetworkManager, you can disable its wait service too:</p> <p>sudo systemctl disable NetworkManager-wait-online.service</p> <p>sudo systemctl mask NetworkManager-wait-online.service</p> <p>\ud83d\udd01 Then reboot your VM: sudo reboot \ud83e\uddea After reboot:</p> <p>Check again: systemd-analyze You should see your boot time drop from 2+ minutes \u2192 ~15 seconds or less.</p> <p>\ud83d\udd01 To Undo the Effects of Disabling and Masking the Wait-Online Service If you previously ran:</p> <ul> <li> <p>sudo systemctl disable systemd-networkd-wait-online.service</p> </li> <li> <p>sudo systemctl mask systemd-networkd-wait-online.service</p> </li> </ul> <p>You can restore the service like this:</p> <p>\u2705 Step 1: Unmask the service</p> <ul> <li>sudo systemctl unmask systemd-networkd-wait-online.service</li> </ul> <p>\u2705 Step 2: Re-enable the service at boot</p> <ul> <li>sudo systemctl enable systemd-networkd-wait-online.service \u2705 Step 3 (Optional): Start it immediately (not needed for reboot use)</li> </ul> <p>sudo systemctl start systemd-networkd-wait-online.service</p> <p>\ud83d\udd01 Same steps apply if you disabled NetworkManager-wait-online.service: Just replace the service name in each command. Example:</p> <p>sudo systemctl unmask NetworkManager-wait-online.service</p> <p>sudo systemctl enable NetworkManager-wait-online.service</p> <p>\ud83e\uddea Confirm it's active again:</p> <p>systemctl status systemd-networkd-wait-online.service or systemctl is-enabled systemd-networkd-wait-online.service</p> <p>You should see:</p> <p><code>enabled</code></p> <p>\u2705 Summary: Rollback Commands</p>"},{"location":"Mac/#unmask-and-re-enable-systemd-networkd-wait-online","title":"Unmask and re-enable systemd-networkd-wait-online","text":"<p>sudo systemctl unmask systemd-networkd-wait-online.service</p> <p>sudo systemctl enable systemd-networkd-wait-online.service</p>"},{"location":"Mac/#optional-also-for-networkmanager-wait-online-if-previously-masked","title":"Optional: Also for NetworkManager-wait-online (if previously masked)","text":"<p>sudo systemctl unmask NetworkManager-wait-online.service</p> <p>sudo systemctl enable NetworkManager-wait-online.service</p>"},{"location":"Matlab/","title":"Matlab","text":"<p>Install this Java Runtime before installing Matlab</p> <p>Java Runtime Required</p> <p>Native Apple silicon MATLAB requires a Java runtime be installed on your Mac. A supported Java 11 JRE is available free of charge with Amazon Corretto 11</p> <p>https://ww2.mathworks.cn/en/support/requirements/apple-silicon.html</p> <p>Had to install Xcode from App store</p>"},{"location":"SSH/","title":"SSH","text":"<p>keypair was created using command like below on windows :</p> <p>ssh-keygen-t ed25519 ...</p> <p>had to convert the private key that was generated on windows using dos2unix as the line endings of the text file generated on windows will be based on carriage return  can check using cat -v ~/.ssh/id_ed25519_private If you see ^M at the end of lines \u2192 that\u2019s a Windows CR (\\r).</p> <p>command to ssh to ncl node 10.13 this does not work (as need to create a config file ): ssh -i ~/.ssh/id_ed25519_private -J ADSC_SmartGrid_5@gateway.ncl.sg -i ~/.ssh/id_ed25519_private pgt@10.10.10.13</p> <p>Create config file first</p> <pre><code># Gateway host\nHost gateway\n    HostName gateway.ncl.sg\n    User ADSC_SmartGrid_5\n    IdentityFile ~/.ssh/id_ed25519_private\n\n# Intermediate host\nHost intermediate\n    HostName 172.18.178.17\n    User pgt\n    Port 4696\n    IdentityFile ~/.ssh/id_ed25519_private\n    ProxyJump gateway\n\n# Final internal host\nHost pgt10.13\n    HostName 10.10.10.13\n    User pgt\n    IdentityFile ~/.ssh/id_ed25519_private\n    ProxyJump intermediate\n\n</code></pre> <p><code>chmod 600 ~/.ssh/config</code> <code>ssh -v pgt10.13</code></p>"},{"location":"ScadaLTS/","title":"ScadaLTS","text":""},{"location":"ScadaLTS/#content-of-docker-composeyml","title":"Content of docker-compose.yml","text":"<p>For Powerplant Twin</p> <pre><code>version: '3.8'\nservices:\n  database:\n    container_name: mysql\n    image: mysql/mysql-server:5.7\n    environment:\n      - MYSQL_ROOT_PASSWORD=root\n      - MYSQL_USER=root\n      - MYSQL_PASSWORD=root\n      - MYSQL_DATABASE=scadalts\n    ports:\n      - \"3307:3306\"\n    volumes:\n      - mysql-data:/var/lib/mysql\n    healthcheck:\n      test: [\"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\", \"-uroot\", \"-proot\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n      start_period: 20s\n\n  scadalts:\n    container_name: scadalts\n    image: scadalts/scadalts:latest\n    depends_on:\n      database:\n        condition: service_healthy\n    ports:\n      - \"8080:8080\"\n    expose:\n      - \"8000\"\n\nvolumes:\n  mysql-data:\n</code></pre>"},{"location":"VM-to-VM-Communication/","title":"VM-to-VM Communication","text":""},{"location":"VM-to-VM-Communication/#for-vm-to-vm-communication-on-virtualbox","title":"FOR VM TO VM COMMUNICATION ON VIRTUALBOX:","text":"<p>Had to use 2 adapters: NAT - enables internet connection for that VM Host only network - make sure to use the SAME host network for both </p>"},{"location":"Wine/","title":"Wine","text":"<p>How Linux WINE Works Under the Hood :</p> <p>https://www.youtube.com/watch?v=XSZ3UJbHqAk</p> <ul> <li>check about file sharing between wine -&gt; ubuntu -&gt; local pc (eg. MacBook)</li> <li>heck about file sharing between wine -&gt; local pc (eg. MacBook)</li> </ul> <p>https://unix.stackexchange.com/questions/344795/is-there-a-program-like-mobaxterm-for-linux-systems-sftp-gui-browser-termina</p>"},{"location":"Wine/#how-to-install-wine-on-ubuntu-2404-lts-linux-running-windows-programs-on-linux","title":"How to Install Wine on Ubuntu 24.04 LTS Linux | Running Windows Programs on Linux","text":"<p>https://youtu.be/J6EkEdQCNaQ?si=1QM9hzJSIiUMwCYW</p>"}]}